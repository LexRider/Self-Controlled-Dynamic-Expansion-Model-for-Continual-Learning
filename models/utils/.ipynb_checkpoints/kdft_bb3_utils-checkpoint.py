import torch.nn as nn

def get_trainable_parameters(model):
    total_params = 0
    trainable_params = 0
    frozen_params = 0

    print(f"{'Parameter Name':<60} {'Trainable':<10} {'Shape':<25} {'#Params'}")
    print("=" * 110)

    for name, param in model.named_parameters():
        numel = param.numel()
        total_params += numel

        if param.requires_grad:
            status = "âœ… Yes"
            trainable_params += numel
        else:
            status = "âŒ No"
            frozen_params += numel

        print(f"{name:<60} {status:<10} {str(tuple(param.shape)):<25} {numel:,}")

    print("=" * 110)
    print(f"ğŸ”¢ Total Parameters      : {total_params:,}")
    print(f"âœ… Trainable Parameters : {trainable_params:,}")
    print(f"âŒ Frozen Parameters    : {frozen_params:,}")

def ablation_unfreeze_backbones(model, name=None):
    import torch
    num_unfrozen = 0

    if name == 'vit':
        print("==> è§£å†» VisionTransformer çš„å 3 å±‚å’Œæ‰€æœ‰ LayerNorm")

        # è§£å†»æœ€å3ä¸ª transformer block
        for block in model.transformer.resblocks[-3:]:
            for param in block.parameters():
                param.requires_grad = True
                num_unfrozen += param.numel()

        # è§£å†» ln_post
        model.ln_post.weight.requires_grad = True
        model.ln_post.bias.requires_grad = True
        num_unfrozen += model.ln_post.weight.numel() + model.ln_post.bias.numel()

        # è§£å†» proj
        model.proj.requires_grad = True
        num_unfrozen += model.proj.numel()

    elif name == 'resnet':
        print("==> è§£å†» ModifiedResNet çš„æœ€åä¸€å±‚å’Œ attnpool")

        for param in model.layer4.parameters():
            param.requires_grad = True
            num_unfrozen += param.numel()

        for param in model.attnpool.parameters():
            param.requires_grad = True
            num_unfrozen += param.numel()

    else:
        raise ValueError(f"Unsupported model type: {type(model)}")

    # ğŸ”„ å°†æ‰€æœ‰å‚æ•°è½¬æˆ float32
    for name, param in model.named_parameters():
        if param.dtype != torch.float32:
            param.data = param.data.float()  # inplace ä¿®æ”¹å‚æ•°å€¼ä¸º float32
            if param._grad is not None:
                param._grad = param._grad.float()  # è‹¥å·²æœ‰æ¢¯åº¦ï¼Œä¹Ÿè½¬æ¢

    print(f"âœ… è§£å†»å®Œæˆï¼Œå…±è§£å†»å‚æ•°æ•°é‡ï¼š{num_unfrozen:,} ä¸ªï¼Œå…¨éƒ¨è½¬ä¸º float32 ç±»å‹")



# def ablation_unfreeze_backbones(model, name = None):
#     # è§£å†»å‚æ•°è®¡æ•°å™¨ï¼ˆå¯é€‰ï¼‰
#     num_unfrozen = 0

#     # Vision Transformer çš„åˆ¤æ–­æ ‡å‡†
#     if name == 'vit':
#         print("==> è§£å†» VisionTransformer çš„å 3 å±‚å’Œæ‰€æœ‰ LayerNorm")
#         # è§£å†»æœ€å3ä¸ª transformer block
#         for block in model.transformer.resblocks[-3:]:
#             for param in block.parameters():
#                 param.requires_grad = True
#                 num_unfrozen += param.numel()

#         # è§£å†» ln_post
#         model.ln_post.weight.requires_grad = True
#         model.ln_post.bias.requires_grad = True
#         num_unfrozen += model.ln_post.weight.numel() + model.ln_post.bias.numel()

#         # è§£å†» proj
#         model.proj.requires_grad = True
#         num_unfrozen += model.proj.numel()

#     # Modified ResNet çš„åˆ¤æ–­æ ‡å‡†
#     elif name == 'resnet':
#         print("==> è§£å†» ModifiedResNet çš„æœ€åä¸€å±‚å’Œ attnpool")
#         # è§£å†»æœ€åä¸€å±‚ layer4
#         for param in model.layer4.parameters():
#             param.requires_grad = True
#             num_unfrozen += param.numel()

#         # è§£å†» attnpool
#         for param in model.attnpool.parameters():
#             param.requires_grad = True
#             num_unfrozen += param.numel()

#     else:
#         raise ValueError(f"Unsupported model type: {type(model)}")

#     print(f"âœ… è§£å†»å®Œæˆï¼Œå…±è§£å†»å‚æ•°æ•°é‡ï¼š{num_unfrozen:,} ä¸ª")